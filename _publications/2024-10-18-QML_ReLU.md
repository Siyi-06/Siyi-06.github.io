---
title: "Efficient quantum circuits for machine learning activation functions including constant T-depth ReLU"
collection: publications
category: manuscripts
permalink: /publication/2024-10-18-QML_ReLU
excerpt: 'In recent years, Quantum Machine Learning (QML) has increasingly captured the interest of researchers. Among the components in this domain, activation functions hold a fundamental and indispensable role. Our research focuses on the development of activation functions quantum circuits for integration into fault-tolerant quantum computing architectures, with an emphasis on minimizing ùëá-depth. Specifically, we present novel implementations of ReLU and leaky ReLU activation functions, achieving constant ùëá-depths of 4 and 8, respectively. Leveraging quantum lookup tables, we extend our exploration to other activation functions such as the sigmoid. This approach enables us to customize precision and ùëá-depth by adjusting the number of qubits, making our results more adaptable to various application scenarios. This study represents a significant advancement towards enhancing the practicality and application of quantum machine learning.'
date: 2024-10-18
venue: 'Physical Review Research'
paperurl: 'https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.6.043048'
citation: 'Zi, Wei, Siyi Wang, Hyunji Kim, Xiaoming Sun, Anupam Chattopadhyay, and Patrick Rebentrost. "Efficient quantum circuits for machine learning activation functions including constant T-depth ReLU." Physical Review Research 6, no. 4 (2024): 043048. http://doi.org/10.1103/PhysRevResearch.6.043048'
---
